{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0249890b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import MolFromSmiles\n",
    "from rdkit.Chem.Fingerprints import FingerprintMols\n",
    "from rdkit.Chem.Descriptors import MolWt\n",
    "from rdkit.Chem.inchi import MolToInchiKey\n",
    "\n",
    "DATA_PATH=\"../data/ReinventResults\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7e70877e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(file):\n",
    "    df=pd.read_csv(file)\n",
    "    \n",
    "    #create eos_id\n",
    "    num=[f\"{i:05}\" for i in range(len(df))]\n",
    "    prefix=\"EOS-\"\n",
    "    batch=str(batchnum)\n",
    "    eos_id=[prefix + batch +\"-\" + x for x in num]\n",
    "    df[\"eosID\"]=eos_id\n",
    "    \n",
    "    #add inchikey identifier\n",
    "    inchikeys=[]\n",
    "    smiles = [x for x in df['SMILES']]\n",
    "    for smi in smiles:\n",
    "        inchikey=MolToInchiKey(MolFromSmiles(smi))\n",
    "        inchikeys += [inchikey]\n",
    "    df[\"InchiKey\"]=inchikeys \n",
    "    \n",
    "    #add molecular weight\n",
    "    molweights=[]\n",
    "    smiles = [x for x in df['SMILES']]\n",
    "    for smi in smiles:\n",
    "        molweight=MolWt(MolFromSmiles(smi))\n",
    "        molweights += [molweight]\n",
    "    df[\"MolWeight\"]=molweights\n",
    "    \n",
    "    #change total_score style\n",
    "    df=df.rename(columns={\"total_score\":\"TotalScore\"})\n",
    "    \n",
    "    #add batch of generation \n",
    "    df[\"Batch\"]=batchnum\n",
    "    \n",
    "    #select columns\n",
    "    df=df[[\"eosID\",\"Batch\",\"SMILES\",\"InchiKey\",\"Scaffold\",\"MolWeight\",\"TotalScore\"]]\n",
    "    \n",
    "    #check if there are compounds from original series 4 batch\n",
    "    original=pd.read_csv(\"../data/OriginalData/series4_allsmiles.csv\") #smiles list must be converted to Inchikey\n",
    "    original_inchikeys=[]\n",
    "    smiles = [x for x in original['canonical']]\n",
    "    for smi in smiles:\n",
    "        original_inchikey=MolToInchiKey(MolFromSmiles(smi))\n",
    "        original_inchikeys += [original_inchikey]\n",
    "    \n",
    "    new_inchikeys=df[\"InchiKey\"].tolist()\n",
    "    duplicates=list(set(original_inchikeys).intersection(new_inchikeys))\n",
    "    if not duplicates:\n",
    "        print(\"there are no repeated Inchikeys from original dataset\")\n",
    "        return df\n",
    "    else:\n",
    "        print(str(len(duplicates))+\" Inchikeys will be eliminated from processed results{}\".format(str(batchnum)))\n",
    "        df=df[~df[\"InchiKey\"].isin(original_inchikeys)]\n",
    "        return df  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27a6a505",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34 Inchikeys will be eliminated from processed results0\n",
      "31 Inchikeys will be eliminated from processed results1\n",
      "4 Inchikeys will be eliminated from processed results2\n",
      "there are no repeated Inchikeys from original dataset\n"
     ]
    }
   ],
   "source": [
    "for results in os.listdir(DATA_PATH):\n",
    "    if \"results_\" in results:\n",
    "        batchnum=int(results.split(\"results_\")[-1])\n",
    "        results_file=os.path.join(DATA_PATH, results, \"scaffold_memory.csv\")\n",
    "        df=process_results(results_file)\n",
    "        df.to_csv(os.path.join(DATA_PATH, \"ProcessedResults\", \"processed{}.csv\".format(batchnum)),index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e6aac39",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_batches_dict={}\n",
    "for file in os.listdir(os.path.join(DATA_PATH, \"ProcessedResults\")):\n",
    "    if \"processed\" in file:\n",
    "        batchnum=file.split(\"processed\")[-1]\n",
    "        batchnum=int(batchnum.strip(\".csv\"))\n",
    "        df=pd.read_csv(os.path.join(DATA_PATH, \"ProcessedResults\", file))\n",
    "        all_batches_dict[batchnum]=df\n",
    "all_batches_df = pd.concat([df for df in all_batches_dict.values()], ignore_index=True)\n",
    "all_batches_df=all_batches_df.drop_duplicates(subset=\"InchiKey\")\n",
    "all_batches_df.to_csv(os.path.join(DATA_PATH, \"ProcessedResults\", \"all_batches.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71a678a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "BitVects must be same length",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-18c303daffcc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfps_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m     \u001b[0msimilarity\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mDataStructs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBulkTanimotoSimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfps_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfps_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m         \u001b[0mquery\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msmiles_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: BitVects must be same length"
     ]
    }
   ],
   "source": [
    "# Calculate similarity among compounds\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df=pd.read_csv(os.path.join(DATA_PATH,\"ProcessedResults\", \"all_batches.csv\"))\n",
    "\n",
    "smiles_list = [x for x in df['SMILES']] #obtain list of smiles\n",
    "mols_list=[MolFromSmiles(x) for x in smiles_list] #create list of mols\n",
    "fps_list=[FingerprintMols.FingerprintMol(x) for x in mols_list] #create list of fingerprints\n",
    "\n",
    "query, target, sim = [] , [], [] #create empty lists for query molecule, comparison molecule and similarity value\n",
    "\n",
    "for fp in range(len(fps_list)-1):\n",
    "    similarity= DataStructs.BulkTanimotoSimilarity(fps_list[fp], fps_list[fp+1:])\n",
    "    for s in range(len(similarity)):\n",
    "        query.append(smiles_list[fp])\n",
    "        target.append(smiles_list[fp+1:][s])\n",
    "        sim.append(similarity[s])\n",
    "d = {'query':query, 'target':target, 'similarity':sim}\n",
    "#df_sim = pd.DataFrame(data=d)\n",
    "        \n",
    "        \n",
    "print(sim[:10])\n",
    "plt.hist(sim[:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5afc80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
